{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ae894f",
   "metadata": {},
   "source": [
    "# 1. Library importation\n",
    "Here the libraries needed for the data manipulation, model and metrics are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c206ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e37ec8",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbcfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['year', 'odometer', 'lat', 'long']\n",
    "categoricalOrdinal_cols = ['model']\n",
    "categoricalHot_cols = ['manufacturer','fuel','drive','type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f5980",
   "metadata": {},
   "source": [
    "## 2.1 Data reading\n",
    "The csv is transformed into a pandas dataframe so we can work with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = numerical_cols+categoricalOrdinal_cols+categoricalHot_cols+['price']\n",
    "df = pd.read_csv('csvs/vehicles.csv', usecols=cols_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae621d9",
   "metadata": {},
   "source": [
    "## 2.2 Price filtering\n",
    "The unreasonably low/high prices are excluded from the dataframe in order to avoid inaccurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21711d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ (df['price'] > 500) & (df['price'] < 100000) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8913577",
   "metadata": {},
   "source": [
    "## 2.3 Target and features\n",
    "The target and features columns are split up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fbdfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[numerical_cols+categoricalHot_cols+categoricalOrdinal_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f62b9f",
   "metadata": {},
   "source": [
    "## 2.4 Imputer\n",
    "A `SimpleImputer` is created in order to organize numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3227546",
   "metadata": {},
   "source": [
    "## 2.5 Encoders\n",
    "Pipelines for categorical data are created. Both firstly use a SimpleImputer to replace null values with the most frequent of said column. Then either a `OneHotEncoder` (for data with lower variety of elements) or an `OrdinalEncoder` (for data with a higher variety of elements) is used in order to make categorical values usable by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encoder = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('hot_encoder', OneHotEncoder(handle_unknown='ignore',sparse_output=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3809f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f8b45",
   "metadata": {},
   "source": [
    "## 2.6 Preprocessor\n",
    "A preprocessor using `ColumnTransformer` is created in order to apply the specific transformations simultaneously, concatenating their results into a final dataset ready for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([('numerical',imputer,numerical_cols),\n",
    "                                  ('ordinal',ordinal_encoder,categoricalOrdinal_cols),\n",
    "                                  ('hot', hot_encoder,categoricalHot_cols)\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a13bc",
   "metadata": {},
   "source": [
    "## 2.7 Splitting data\n",
    "`train_test_split` is used in order to randomly select data for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d008d6",
   "metadata": {},
   "source": [
    "## 2.8 Data transformation\n",
    "The preprocessor is trained only with the training data and then transforms both the valid and train features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X_train)\n",
    "X_valid=preprocessor.transform(X_valid)\n",
    "X_train=preprocessor.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df36418",
   "metadata": {},
   "source": [
    "# 3. Model training\n",
    "The `XGBRegressor` model is created with the most optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGBRegressor(n_jobs=-1,learning_rate=0.03,n_estimators=5000,early_stopping_rounds=50,max_depth=12,random_state=1,min_child_weight=3,subsample=0.7,colsample_bytree=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0200f37",
   "metadata": {},
   "source": [
    "## 3.1 Model fitting\n",
    "The model trains with the training data while using the validation data as its `eval_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(X_train,y_train,verbose=False,eval_set=[(X_valid,y_valid)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc0dac",
   "metadata": {},
   "source": [
    "# 4. Results\n",
    "Both the `mean_absolute_error` and `mean_absolute_percentage_error` of the train and validation data are calculated so it is easier to see if any overfitting happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final_model.predict(X_valid)\n",
    "mae=mean_absolute_error(predictions,y_valid)\n",
    "train_preds=final_model.predict(X_train)\n",
    "mae_train=mean_absolute_error(train_preds,y_train)\n",
    "print(f'mae valid: {mae}')\n",
    "print(f'mae train: {mae_train}')\n",
    "mape=mean_absolute_percentage_error(predictions,y_valid)\n",
    "print(mape)\n",
    "mape_train=mean_absolute_percentage_error(train_preds,y_train)\n",
    "print(mape_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763b661",
   "metadata": {},
   "source": [
    "# 5 Exporting\n",
    "Saves the files to use it in FastAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(preprocessor, 'car_preprocessor.pkl')\n",
    "joblib.dump(final_model,'car_price_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
